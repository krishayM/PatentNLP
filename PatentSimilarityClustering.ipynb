{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PatentSimilarityClustering.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMEMsGmipNuG"
      },
      "source": [
        "!git clone https://github.com/lo1gr/medical_document_clustering.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khoX0UvLq_Vg"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGEIsH0Br3J1"
      },
      "source": [
        "pip install bert-embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BlA8RYzrLBJ"
      },
      "source": [
        "# Libraries\n",
        "import pandas as pd\n",
        "\n",
        "from medical_document_clustering.embeddings import Bert, BioWordVec, ELMo, GoogleSentence, Word2Vec\n",
        "from repository.preprocessing import launch_preprocessing\n",
        "from modeling import KMeansModel, DBSCANModel, AffinityPropagationModel, BirchModel, OPTICSModel, ClusterLabelsCombiner\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnH38oQMqyHK"
      },
      "source": [
        "\n",
        "# Constants\n",
        "\n",
        "random_state = 42\n",
        "\n",
        "# Do not forget to fetch data from data_collection notebook\n",
        "\n",
        "abstracts_path = '/content/drive/My Drive/patents2017DescOnlyNoStopwordsNoNumbers.csv'\n",
        "\n",
        "# Core functions\n",
        "\n",
        "\n",
        "def embed_abstracts(abstracts, embedding_type):\n",
        "\n",
        "    model = None\n",
        "\n",
        "    if embedding_type == \"word2vec\":\n",
        "        model = Word2Vec()\n",
        "        vectors, output_format = model.embed_text(abstracts.nouns_lemmatized_text)\n",
        "\n",
        "    elif embedding_type == \"biowordvec\":\n",
        "        model = BioWordVec()\n",
        "        vectors, output_format = model.embed_text(abstracts.nouns_lemmatized_text)\n",
        "\n",
        "    elif embedding_type == \"google_sentence\":\n",
        "        model = GoogleSentence()\n",
        "        vectors, output_format = model.embed_text(abstracts.sentence_tokens)\n",
        "\n",
        "    elif embedding_type == \"elmo\":\n",
        "        model = ELMo()\n",
        "        vectors, output_format = model.embed_text(abstracts.nouns_lemmatized_text.apply(\" \".join))\n",
        "\n",
        "    elif embedding_type == \"bert\":\n",
        "        model = Bert()\n",
        "        vectors, output_format = model.embed_text(abstracts.nouns_lemmatized_text.apply(\" \".join))\n",
        "\n",
        "    else:\n",
        "        raise Exception(\"Embedding type should be word2vec, biowordvec, google_sentence, elmo or bert\")\n",
        "\n",
        "    return vectors, output_format, model\n",
        "\n",
        "\n",
        "abstracts = pd.read_excel(abstracts_path)\n",
        "abstracts = launch_preprocessing(abstracts)\n",
        "\n",
        "vectors_biowordvec, output_format_biowordvec, model_biowordvec = embed_abstracts(abstracts, \"biowordvec\")\n",
        "\n",
        "vectors_bert, output_format_bert, model_bert = embed_abstracts(abstracts, \"bert\")\n",
        "\n",
        "# vectors_gs, output_format_gs, model_gs = embed_abstract(abstracts, \"google_sentence\")\n",
        "\n",
        "\n",
        "# Modeling\n",
        "\n",
        "# KMeans\n",
        "\n",
        "n_clusters = 100\n",
        "\n",
        "model_kmeans = KMeansModel(n_clusters=n_clusters)\n",
        "\n",
        "model_kmeans.plot_elbow(features=vectors_biowordvec, range=range(10, 40, 2))\n",
        "\n",
        "model_kmeans = model_kmeans.set_model_parameters(n_clusters=n_clusters)\n",
        "clusters = model_kmeans.perform_clustering(features=vectors_biowordvec)\n",
        "model_kmeans.plot_from_pca(clusters=clusters)\n",
        "\n",
        "labelled_clusters = model_kmeans.label_clusters(clusters=clusters, abstracts=abstracts)\n",
        "\n",
        "rmse_kmeans = KMeansModel.evaluate_clusters(embedder=model_biowordvec, labelled_clusters=labelled_clusters)\n",
        "\n",
        "model_kmeans.nb_categories_in_clusters(labelled_clusters=labelled_clusters)\n",
        "\n",
        "\n",
        "# DBSCAN\n",
        "\n",
        "eps = 0.1\n",
        "min_samples = 5\n",
        "\n",
        "model_dbscan = DBSCANModel(eps=eps, min_samples=min_samples, metric=\"cosine\")\n",
        "\n",
        "clusters = model_dbscan.perform_clustering(features=vectors_biowordvec)\n",
        "model_dbscan.plot_from_pca(clusters=clusters)\n",
        "\n",
        "labelled_clusters = model_dbscan.label_clusters(clusters=clusters, abstracts=abstracts)\n",
        "\n",
        "\n",
        "# OPTICS\n",
        "\n",
        "min_samples = 20\n",
        "\n",
        "model_optics = OPTICSModel(min_samples=min_samples,  metric=\"cosine\")\n",
        "\n",
        "clusters = model_optics.perform_clustering(features=vectors_biowordvec)\n",
        "model_optics.plot_from_pca(clusters=clusters)\n",
        "\n",
        "labelled_clusters = model_optics.label_clusters(clusters=clusters, abstracts=abstracts)\n",
        "\n",
        "\n",
        "# Affinity Propagation\n",
        "\n",
        "model_affinity = AffinityPropagationModel()\n",
        "\n",
        "clusters = model_affinity.perform_clustering(features=vectors_biowordvec)\n",
        "model_affinity.plot_from_pca(clusters=clusters)\n",
        "\n",
        "labelled_clusters = model_affinity.label_clusters(clusters=clusters, abstracts=abstracts)\n",
        "\n",
        "\n",
        "# Birch\n",
        "\n",
        "model_birch = BirchModel(n_clusters=n_clusters)\n",
        "\n",
        "clusters = model_birch.perform_clustering(features=vectors_biowordvec)\n",
        "model_birch.plot_from_pca(clusters=clusters)\n",
        "\n",
        "labelled_clusters = model_birch.label_clusters(clusters=clusters, abstracts=abstracts)\n",
        "\n",
        "\n",
        "# Clusters Combiner\n",
        "\n",
        "\"\"\"\n",
        "Use it if you chose to export the preprocessed abstracts in order not to compute preprocessing every time\n",
        "\n",
        "abstracts = pd.read_csv('data/abstracts_preprocessed.csv',\n",
        "                        converters={\n",
        "                            \"nouns_lemmatized_title\": lambda x: x.strip(\"[]\").replace(\"'\", \"\").split(\", \"),\n",
        "                            \"nouns_lemmatized_text\": lambda x: x.strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
        "                        })\n",
        "\"\"\"\n",
        "\n",
        "clc = ClusterLabelsCombiner([\n",
        "    (KMeansModel(n_clusters=100), vectors_biowordvec),\n",
        "    (AffinityPropagationModel(), vectors_biowordvec),\n",
        "    (BirchModel(n_clusters=100), vectors_biowordvec),\n",
        "    (KMeansModel(n_clusters=150), vectors_bert),\n",
        "    (BirchModel(n_clusters=150), vectors_bert)\n",
        "])\n",
        "\n",
        "labels = clc.combine(abstracts=abstracts, number_of_tags_to_keep=5)\n",
        "\n",
        "rmse = clc.evaluate(embedder=model_biowordvec, abstracts=abstracts)\n",
        "\n",
        "final = pd.concat([labels.labels, abstracts], axis=1)\n",
        "\n",
        "final.to_csv('abstracts_labelled.csv', index=None)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
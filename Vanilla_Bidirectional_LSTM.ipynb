{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vanilla Bidirectional LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oipBciH5E9n"
      },
      "source": [
        "import numpy as np\n",
        "import pickle \n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, Bidirectional, SpatialDropout1D\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PU6FWcM65PEY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34464114-cb2b-4c3f-cdc0-088741986fb1"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')\n",
        "DATA_PATH = \"/content/gdrive/My Drive\"\n",
        "tech_infile = open(DATA_PATH+'/technologies.pkl','rb')\n",
        "tech_pkl = pickle.load(tech_infile)\n",
        "\n",
        "infile = open(DATA_PATH+'/abstracts.pkl','rb')\n",
        "abs_pkl = pickle.load(infile)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0C1BY35Hmes"
      },
      "source": [
        "indexlist = list(set(tech_pkl.values()))\n",
        "df = pd.read_stata('gdrive/My Drive/public_pat_var20200908.dta')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUxTZ3ukQHUr"
      },
      "source": [
        "df_a = pd.DataFrame(abs_pkl.items())\n",
        "df_a.columns = ['patent', 'abstract']\n",
        "\n",
        "#df['patent'] = pd.to_numeric(df['patent'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kaj4XOafIlKi"
      },
      "source": [
        "#for idx in indexlist:\n",
        "\n",
        "pat_ids = [float(i) for i in tech_pkl if tech_pkl[i]==16] #Patent Id's associated to a certain industry (In this case Pharma, I looked up the indexes from one of the excels Hari had sent us)\n",
        "pid_str = [str(s) for s in pat_ids]\n",
        "df_n=df[df['patent'].isin(pat_ids)] \n",
        "df_n = df_n.filter(['qje_adj_xi'], axis=1)  #Industry specific kogan scores dataframe\n",
        "df_abs = df_a[df_a['patent'].isin(pid_str)] #Industry specific abstracts dataframe\n",
        "\n",
        "#df_abs = df_abs.filter(['abstract'], axis=1) \n",
        "#abs_data = df_abs.to_numpy()#x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYZ13yPkgbDe"
      },
      "source": [
        "MAX_NB_WORDS = 10000\n",
        "MAX_SEQ_LENGTH = 400\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
        "tokenizer.fit_on_texts(df_abs['abstract'].values)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "#print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "X = tokenizer.texts_to_sequences(df_abs['abstract'].values)\n",
        "X = pad_sequences(X, maxlen=MAX_SEQ_LENGTH)\n",
        "\n",
        "#print('Shape of data tensor:', X.shape)\n",
        "\n",
        "Y = df_n.to_numpy()\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.10, random_state = 42)\n",
        "Y_train = Y_train.astype(float)\n",
        "#Y_train = np.log(Y_train)\n",
        "Y_test = Y_test.astype(float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXEZM-EEfw1-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f51bfaa-7bab-462e-f75c-e5397b697e43"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)))\n",
        "#model.add(Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)))\n",
        "model.add(Dense(13, activation='relu'))\n",
        "model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 400, 100)          1000000   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d (SpatialDr (None, 400, 100)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 200)               160800    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 13)                2613      \n",
            "=================================================================\n",
            "Total params: 1,163,413\n",
            "Trainable params: 1,163,413\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6QBeQkQkHcj"
      },
      "source": [
        "epochs = 500\n",
        "batch_size = 64\n",
        "\n",
        "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n",
        "\n",
        "accr = model.evaluate(X_test,Y_test)\n",
        "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}